{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1E4sdAglR7cVY4xstxlZ3iBob2RdAb6eO","authorship_tag":"ABX9TyOV9SSn5Lc5z3gV9knGdJdd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -U datasets transformers"],"metadata":{"id":"vRtScSGNYkkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKY2ir0KS_kb"},"outputs":[],"source":["# Import required libraries\n","import numpy as np\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"]},{"cell_type":"markdown","source":["This code verifies if a GPU is available and prints its name if found. This is important for accelerating the training process."],"metadata":{"id":"ew9-aco3uY7K"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"Mab6WOV9qjlm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# Check if GPU is available\n","print(\"GPU Available:\", torch.cuda.is_available())\n","\n","# Print GPU name\n","if torch.cuda.is_available():\n","    print(\"GPU Name:\", torch.cuda.get_device_name(0))"],"metadata":{"id":"jhOfd7uGhzZR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Loading and Preprocessing**\n","This section loads the consumer complaints data from a CSV file,\n","preprocesses it by renaming columns, and creates a label mapping for the target variable."],"metadata":{"id":"eqn9ft0FuNoJ"}},{"cell_type":"code","source":["# 1. Load and Preprocess the Data\n","# --------------------------------\n","# Assume you have downloaded the CSV locally (e.g., 'consumer_complaints.csv').\n","# Here, we load the CSV, rename columns to standardize (e.g. lower-case with underscores),\n","# and then create a label mapping for the target variable (\"product\").\n","\n","complaints_df = pd.read_csv(\"/content/complaints-2025.csv\")"],"metadata":{"id":"eslr5RrTTLUF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complaints_df.shape"],"metadata":{"id":"VI4QjE-eTsD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complaints_df.info()"],"metadata":{"id":"YIha9fZiTtpY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complaints_df.head(10)"],"metadata":{"id":"eWvofXscVueL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["issues_df = complaints_df.Issue.value_counts().reset_index()"],"metadata":{"id":"KTVyTIySV-f-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["issues_df.head(10)"],"metadata":{"id":"yuUtssmXWlX2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_labels = len(issues_df.Issue.unique())"],"metadata":{"id":"GZUq5_wSaE-P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_labels"],"metadata":{"id":"cUbbo1CzaI3R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Here, we select the relevant columns for text classification (narrative and issue) and rename them for clarity.\n"],"metadata":{"id":"X1Liu72gucz5"}},{"cell_type":"code","source":["complaints_df = complaints_df[[\"Consumer complaint narrative\", \"Issue\"]].dropna().reset_index()"],"metadata":{"id":"f7jva1FOTjuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["complaints_df.info()"],"metadata":{"id":"XM0khWxoXjgy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = complaints_df[['Consumer complaint narrative', 'Issue']]\n","df.columns = ['Narrative', 'labels']"],"metadata":{"id":"nzKqak4HYHwI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section converts the pandas DataFrame to a Hugging Face Dataset and encodes the labels for classification."],"metadata":{"id":"yNhlqHPCuhiX"}},{"cell_type":"code","source":["# Convert the pandas DataFrame to a Hugging Face Dataset\n","dataset = Dataset.from_pandas(df)\n","\n","dataset = dataset.class_encode_column(\"labels\")"],"metadata":{"id":"AopfsYhjTQga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get label mapping as a dictionary\n","label_mapping = {idx: label for idx, label in enumerate(dataset.features[\"labels\"].names)}\n","\n","# Print dictionary\n","label_mapping\n"],"metadata":{"id":"eO6WXIZJfl12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split into train and test sets (80-20 split)\n","dataset = dataset.train_test_split(test_size=0.2)\n","train_dataset = dataset[\"train\"]\n","eval_dataset = dataset[\"test\"]"],"metadata":{"id":"aIyNZCoefbvP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section defines a function to tokenize the text data using the chosen model's tokenizer. It then applies the tokenization to both training and evaluation datasets."],"metadata":{"id":"Yh2h-sFcukZk"}},{"cell_type":"code","source":["# 2. Tokenize the Data\n","# ---------------------\n","# Load the tokenizer from the chosen model and define a function to tokenize each example.\n","model_name = \"ProsusAI/finbert\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize_function(example):\n","    # Tokenize the complaint narrative text.\n","    return tokenizer(\n","        example[\"Narrative\"],\n","        truncation=True,\n","        padding=True,\n","        max_length=128  # adjust max_length based on your data and available compute\n","    )"],"metadata":{"id":"hCpAtWpaYgSy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the tokenization to both train and evaluation datasets.\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","eval_dataset = eval_dataset.map(tokenize_function, batched=True)"],"metadata":{"id":"wK5vTPYQZm_-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_dataset.column_names)  # Should include 'input_ids', 'attention_mask', and 'labels'"],"metadata":{"id":"1i0pTe6Wcqbs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove unnecessary columns (keeping only the input IDs, attention masks, and label)\n","columns_to_remove = [col for col in train_dataset.column_names if col not in [\"input_ids\", \"attention_mask\", \"labels\"]]\n","train_dataset = train_dataset.remove_columns(columns_to_remove)\n","eval_dataset = eval_dataset.remove_columns(columns_to_remove)\n","\n","# Set the format for PyTorch (so that the Trainer can work with torch tensors)\n","train_dataset.set_format(\"torch\")\n","eval_dataset.set_format(\"torch\")"],"metadata":{"id":"ovApCXUCZpM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This function generator creates a compute_metrics function based on the provided configuration.\n","\n","You can set which metrics to compute by modifying the metric_config dictionary.\n"],"metadata":{"id":"JZk8NuIluusQ"}},{"cell_type":"code","source":["# 3. Define a Configurable Metrics Function\n","# ------------------------------------------\n","# This function generator creates a compute_metrics function based on the provided configuration.\n","# You can set which metrics to compute by modifying the metric_config dictionary.\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    metrics = {}\n","    # Always compute accuracy\n","    metrics[\"accuracy\"] = accuracy_score(labels, predictions)\n","\n","    return metrics"],"metadata":{"id":"CkGf7h72Zs8G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section loads the pre-trained FinBERT model, specifying the number of labels for our classification task.\n"],"metadata":{"id":"c8nsMvE2uxrp"}},{"cell_type":"code","source":["# 4. Load and Configure the Model\n","# --------------------------------\n","# For a classification task, we load a pre-trained model for sequence classification and specify the number of labels.\n","model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, ignore_mismatched_sizes=True)"],"metadata":{"id":"HCkFGX55Zyn9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code defines the hyperparameters and settings for the training process, such as learning rate, batch size, and number of epochs.\n"],"metadata":{"id":"H8ZHsOqNu2le"}},{"cell_type":"code","source":["# 5. Set Up Training Arguments\n","# -----------------------------\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",             # output directory\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    report_to=\"none\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,                 # adjust epochs based on your task\n","    weight_decay=0.01,\n","    logging_steps=50,\n","    load_best_model_at_end=True,\n","    fp16=True,\n","#    tpu_num_cores=8,  # Use all 8 TPU cores\n",")"],"metadata":{"id":"6QFC4MKHZ1NN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section initializes the Trainer with the model, training arguments, and datasets, and then starts the fine-tuning process."],"metadata":{"id":"nBiVo_vNu7wa"}},{"cell_type":"code","source":["# 6. Initialize the Trainer and Fine-Tune the Model\n","# --------------------------------------------------\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,  # pass our configurable metrics function\n","    processing_class=tokenizer,\n",")\n","\n","# Fine-tune the model\n","trainer.train()"],"metadata":{"id":"tT6fs7AlaM6H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optionally, evaluate the model\n","eval_results = trainer.evaluate()\n","print(\"Evaluation results:\", eval_results)"],"metadata":{"id":"J6qpYhJZag9q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This code saves the trained model and tokenizer for later use.\n"],"metadata":{"id":"95sTEKA1u-0m"}},{"cell_type":"code","source":["# 7. Save the Fine-Tuned Model and Tokenizer\n","# -------------------------------------------\n","# After training, save the model and tokenizer so that you can load them later for inference.\n","model_save_path = \"./modelnew\"\n","trainer.save_model(model_save_path)  # Saves the model\n","tokenizer.save_pretrained(model_save_path)  # Saves the tokenizer\n","\n","print(f\"Model and tokenizer saved to {model_save_path}\")\n"],"metadata":{"id":"zPkVHR1AoMqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section demonstrates how to use the trained model to classify new consumer complaints and print the predictions.\n"],"metadata":{"id":"1OeJv8CGvAoD"}},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n","\n","# 8. Load the Saved Model and Tokenizer\n","# -------------------------------------\n","loaded_model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n","loaded_tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n","\n","# Create a text classification pipeline using the loaded model and tokenizer\n","classifier = pipeline(\"text-classification\", model=loaded_model, tokenizer=loaded_tokenizer)"],"metadata":{"id":"iyuGW71moUBF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section demonstrates how to use the trained model to classify new consumer complaints and print the predictions.\n"],"metadata":{"id":"_Qxs56MBvDAy"}},{"cell_type":"code","source":["# 9. Classify New Consumer Complaints\n","# ------------------------------------\n","# List of new complaint texts to classify.\n","new_complaints = [\n","    \"I am extremely disappointed with the bank's customer service and hidden fees.\",\n","    \"My credit card company continues to charge me for services I never signed up for.\",\n","    \"The mortgage process was unclear and misleading. I'm not sure I got what I was promised.\"\n","]\n","\n","# Get predictions for the new complaints.\n","predictions = classifier(new_complaints)\n","\n","# Print out the predictions.\n","for complaint, pred in zip(new_complaints, predictions):\n","    print(f\"Complaint: {complaint}\")\n","    print(f\"Prediction: {pred}\\n\")"],"metadata":{"id":"jnw1YaxYoYO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_mapping\n"],"metadata":{"id":"7K3qJi9apAjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get raw predictions on the test set\n","predictions_output = trainer.predict(eval_dataset)\n","\n","# Extract logits and true labels\n","logits = predictions_output.predictions\n","true_labels = predictions_output.label_ids\n","\n","# Convert logits to predicted class indices\n","predicted_labels = np.argmax(logits, axis=-1)\n"],"metadata":{"id":"OQHq6mwZoY6o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This section calculates and displays the confusion matrix to evaluate the performance of the trained model.\n"],"metadata":{"id":"60XVDASzvGbx"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Compute confusion matrix\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","# Print the raw confusion matrix\n","print(\"Confusion Matrix:\\n\", conf_matrix)"],"metadata":{"id":"tBEIa6VqpOSP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","label_names = list(label_mapping.values())\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_names, yticklabels=label_names)\n","\n","# Labels and title\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"ZkEdlNWOpUV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1yzkMUc6pdTz"},"execution_count":null,"outputs":[]}]}